{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MSE: 622911.006097155\n",
            "Testing MSE: 23967492126.902058\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data=pd.read_csv('work_20000.csv')\n",
        "data.reindex()\n",
        "data.head(5)\n",
        "# data.dropna(subset=['TITLE'],inplace=True)\n",
        "data.dropna()\n",
        "data['TITLE'].isnull().sum()\n",
        "data.fillna(\" \",inplace=True)\n",
        "data['TAGS']=data['TITLE']+\" \"+data['BULLET_POINTS']+\" \"+data['DESCRIPTION']\n",
        "\n",
        "data['TAGS'] = data['TAGS'].astype(str)\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "data['TAGS']=data['TAGS'].apply(lambda x: x.lower())\n",
        "\n",
        "dirt=[']','_','[','(',')',':',';',\"''\",'{','}','<','>','/','\\\\','|','\\'','@','#','$','%','^','&','*','+','=','~','`','1','2','3','4','5','6','7','8','9','0','-']\n",
        "def dirtRemover(text):\n",
        "    text=text.replace('[^\\w\\s]','').replace('\\s\\s+', ' ')\n",
        "    text=re.sub(r'-?\\d+\\.\\d+', '', text)\n",
        "    text=re.sub('-?\\d+',' ',text)\n",
        "    text=re.sub(r'[^\\w\\s]','',text).replace(\"_\",\"\")\n",
        "    \n",
        "    # # POS tagging\n",
        "    words = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    filtered_words = []\n",
        "    for word, pos_tag in pos_tags:\n",
        "        if pos_tag in ['NN', 'NNS']:\n",
        "            filtered_words.append(word.lower())\n",
        "\n",
        "    # Remove stop words and dirt words\n",
        "    filtered_words = [word for word in filtered_words if word not in stop_words]\n",
        "    filtered_words = [word for word in filtered_words if word not in dirt]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_tags = []\n",
        "    for tag in filtered_words:\n",
        "        if(len(tag)>3):\n",
        "            stemmed_tag = stemmer.stem(tag)\n",
        "            stemmed_tags.append(stemmed_tag)\n",
        "    return stemmed_tags\n",
        "\n",
        "data['TAGS']=data['TAGS'].apply(dirtRemover)\n",
        "data=data.drop(columns=['TITLE','BULLET_POINTS','DESCRIPTION','PRODUCT_ID','Unnamed: 0'],axis=1)\n",
        "data['TAGS'] = data['TAGS'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "data.head(25)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = data['TAGS']\n",
        "y = data['PRODUCT_LENGTH']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Convert tags to vectors using CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=50000, stop_words='english')\n",
        "X_train_vectors = cv.fit_transform(X_train)\n",
        "X_test_vectors = cv.transform(X_test)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_vectors, y_train)\n",
        "\n",
        "# Evaluate model on training set\n",
        "y_train_pred = model.predict(X_train_vectors)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "print('Training MSE:', mse_train)\n",
        "\n",
        "# Evaluate model on testing set\n",
        "y_test_pred = model.predict(X_test_vectors)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "print('Testing MSE:', mse_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
